{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimirzaigrajew/Documents/projects/ClipAligner/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.models.models import *\n",
    "from src.models.aligner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = torch.rand(1, 3, 224, 224)\n",
    "sample_test = [\"Wlazl kotek na plotek i mruga\"]\n",
    "batch_sample_image = torch.rand(2, 3, 224, 224)\n",
    "batch_sample_test = [\"Wlazl kotek na plotek i mruga\", \"Wlazl kotek na plotek i mruga na ciebie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dinov2_vits14': (384, 256),\n",
       " 'dinov2_vitb14': (768, 256),\n",
       " 'dinov2_vitl14': (1024, 256),\n",
       " 'dinov2_vitg14': (1536, 256)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dino_family = DinoVisionModel\n",
    "dino_family.SHAPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-23 20:59:03.821\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n",
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "xFormers not available\n",
      "xFormers not available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DinoVisionModel(\n",
       "  (_model): DinoVisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x NestedTensorBlock(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MemEffAttention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dino = dino_family(checkpoint=\"dinov2_vitb14\", pooling=\"cls\")\n",
    "base_dino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimirzaigrajew/Documents/projects/ClipAligner/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 224, 224]), torch.Size([2, 768]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = transforms.Compose(base_dino.get_basic_transformations())\n",
    "trans(sample_image).shape, base_dino(sample_image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    output_image = base_dino(trans(sample_image))\n",
    "    output_batch_image = base_dino(trans(batch_sample_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 768]), torch.Size([2, 768]), 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_image.shape, output_batch_image.shape, base_dino.output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-23 20:59:09.159\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 20:59:10.865\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, checkpoint: dinov2_vits14, output_dim: 384, output_shape: torch.Size([2, 384]), batch_output_shape: torch.Size([2, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 20:59:14.711\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, checkpoint: dinov2_vitb14, output_dim: 768, output_shape: torch.Size([2, 768]), batch_output_shape: torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 20:59:16.378\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, checkpoint: dinov2_vits14, output_dim: 256, output_shape: torch.Size([2, 256]), batch_output_shape: torch.Size([2, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 20:59:19.800\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, checkpoint: dinov2_vitb14, output_dim: 256, output_shape: torch.Size([2, 256]), batch_output_shape: torch.Size([2, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 20:59:20.810\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: max, checkpoint: dinov2_vits14, output_dim: 256, output_shape: torch.Size([2, 256]), batch_output_shape: torch.Size([2, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 20:59:24.111\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: max, checkpoint: dinov2_vitb14, output_dim: 256, output_shape: torch.Size([2, 256]), batch_output_shape: torch.Size([2, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 20:59:25.137\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, checkpoint: dinov2_vits14, output_dim: 512, output_shape: torch.Size([2, 512]), batch_output_shape: torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 20:59:28.421\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, checkpoint: dinov2_vitb14, output_dim: 512, output_shape: torch.Size([2, 512]), batch_output_shape: torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 20:59:29.748\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean, checkpoint: dinov2_vits14, output_dim: 640, output_shape: torch.Size([2, 640]), batch_output_shape: torch.Size([2, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 20:59:32.818\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean, checkpoint: dinov2_vitb14, output_dim: 1024, output_shape: torch.Size([2, 1024]), batch_output_shape: torch.Size([2, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 20:59:33.714\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_max, checkpoint: dinov2_vits14, output_dim: 640, output_shape: torch.Size([2, 640]), batch_output_shape: torch.Size([2, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 20:59:37.391\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_max, checkpoint: dinov2_vitb14, output_dim: 1024, output_shape: torch.Size([2, 1024]), batch_output_shape: torch.Size([2, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 20:59:38.756\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, checkpoint: dinov2_vits14, output_dim: 896, output_shape: torch.Size([2, 896]), batch_output_shape: torch.Size([2, 896])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, checkpoint: dinov2_vitb14, output_dim: 1280, output_shape: torch.Size([2, 1280]), batch_output_shape: torch.Size([2, 1280])\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    for pooler in [\"cls\", \"mean\", \"max\", \"mean_max\", \"cls_mean\", \"cls_max\", \"cls_mean_max\"]:\n",
    "        for checkpoint in [\"dinov2_vits14\", \"dinov2_vitb14\"]:#, \"dinov2_vitl14\", \"dinov2_vitg14\"]:\n",
    "            dino = dino_family(checkpoint=checkpoint, pooling=pooler)\n",
    "            print(f\"pooler: {pooler}, checkpoint: {checkpoint}, output_dim: {dino.output_dim}, output_shape: {dino(sample_image).shape}, batch_output_shape: {dino(batch_sample_image).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-23 20:59:41.814\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n",
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Pooling Wrong is not supported for DinoVisionModel.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/vladimirzaigrajew/Documents/projects/ClipAligner/notebooks/models_validation.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vladimirzaigrajew/Documents/projects/ClipAligner/notebooks/models_validation.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dino_family(checkpoint\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdinov2_vits14\u001b[39;49m\u001b[39m\"\u001b[39;49m, pooling\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mWrong\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/projects/ClipAligner/notebooks/../src/models/models.py:25\u001b[0m, in \u001b[0;36mDinoVisionModel.__init__\u001b[0;34m(self, checkpoint, pooling, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     24\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_model \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mhub\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mfacebookresearch/dinov2\u001b[39m\u001b[39m'\u001b[39m, checkpoint)\n\u001b[0;32m---> 25\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pooler, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_dim \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_pooler_fn(pooling, checkpoint)\n\u001b[1;32m     26\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transform \u001b[39m=\u001b[39m [\n\u001b[1;32m     27\u001b[0m     transforms\u001b[39m.\u001b[39mResize(\u001b[39m244\u001b[39m), transforms\u001b[39m.\u001b[39mCenterCrop(\u001b[39m224\u001b[39m), transforms\u001b[39m.\u001b[39mNormalize([\u001b[39m0.5\u001b[39m], [\u001b[39m0.5\u001b[39m])\n\u001b[1;32m     28\u001b[0m ]\n",
      "File \u001b[0;32m~/Documents/projects/ClipAligner/notebooks/../src/models/models.py:63\u001b[0m, in \u001b[0;36mDinoVisionModel._get_pooler_fn\u001b[0;34m(pooler, checkpoint)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m x: torch\u001b[39m.\u001b[39mcat([x[\u001b[39m'\u001b[39m\u001b[39mx_norm_clstoken\u001b[39m\u001b[39m'\u001b[39m], x[\u001b[39m'\u001b[39m\u001b[39mx_norm_patchtokens\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmean(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), x[\u001b[39m'\u001b[39m\u001b[39mx_norm_patchtokens\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmax(dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), DinoVisionModel\u001b[39m.\u001b[39mSHAPES[checkpoint][\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m DinoVisionModel\u001b[39m.\u001b[39mSHAPES[checkpoint][\u001b[39m1\u001b[39m] \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m     62\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPooling \u001b[39m\u001b[39m{\u001b[39;00mpooler\u001b[39m}\u001b[39;00m\u001b[39m is not supported for \u001b[39m\u001b[39m{\u001b[39;00mDinoVisionModel\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Pooling Wrong is not supported for DinoVisionModel."
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dino_family(checkpoint=\"dinov2_vits14\", pooling=\"Wrong\")\n",
    "    assert False\n",
    "except ValueError:\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roberta-base': 768, 'roberta-large': 1024, 'xlm-roberta-base': 250002}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robert_family = RobertaCaptionModel\n",
    "robert_family.SHAPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-23 21:41:20.784\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 21:41:23.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaCaptionModel(\n",
       "  (_model): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_robert = robert_family(checkpoint=\"roberta-base\", pooling=\"cls\")\n",
    "base_robert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['input_ids', 'attention_mask']),\n",
       " dict_keys(['input_ids', 'attention_mask']))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = base_robert.get_tokenizer()\n",
    "tokenizer(sample_test, return_tensors=\"pt\", padding=True).keys(), tokenizer(batch_sample_test, return_tensors=\"pt\", padding=True).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    output_test = base_robert(tokenizer(sample_test, return_tensors=\"pt\", padding=True))\n",
    "    output_batch_test = base_robert(tokenizer(batch_sample_test, return_tensors=\"pt\", padding=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 768]), torch.Size([2, 768]), 768)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test.shape, output_batch_test.shape, base_robert.output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-23 21:41:23.461\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 21:41:25.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 21:41:25.579\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, checkpoint: roberta-base, output_dim: 768, output_shape: torch.Size([1, 768]), batch_output_shape: torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-11-23 21:41:31.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 21:41:31.478\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, checkpoint: xlm-roberta-base, output_dim: 250002, output_shape: torch.Size([1, 250002]), batch_output_shape: torch.Size([2, 250002])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 21:41:32.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 21:41:33.394\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, checkpoint: roberta-base, output_dim: 768, output_shape: torch.Size([1, 15]), batch_output_shape: torch.Size([2, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-11-23 21:41:38.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 21:41:39.061\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, checkpoint: xlm-roberta-base, output_dim: 250002, output_shape: torch.Size([1, 15]), batch_output_shape: torch.Size([2, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 21:41:40.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 21:41:41.415\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: max, checkpoint: roberta-base, output_dim: 768, output_shape: torch.Size([1, 768]), batch_output_shape: torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-11-23 21:41:46.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 21:41:46.891\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: max, checkpoint: xlm-roberta-base, output_dim: 250002, output_shape: torch.Size([1, 250002]), batch_output_shape: torch.Size([2, 250002])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 21:41:48.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 21:41:49.396\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, checkpoint: roberta-base, output_dim: 1536, output_shape: torch.Size([1, 1536]), batch_output_shape: torch.Size([2, 1536])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-11-23 21:41:54.477\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 21:41:54.732\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, checkpoint: xlm-roberta-base, output_dim: 500004, output_shape: torch.Size([1, 500004]), batch_output_shape: torch.Size([2, 500004])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 21:41:56.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 21:41:56.765\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean, checkpoint: roberta-base, output_dim: 1536, output_shape: torch.Size([1, 1536]), batch_output_shape: torch.Size([2, 1536])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-11-23 21:42:02.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 21:42:02.818\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean, checkpoint: xlm-roberta-base, output_dim: 500004, output_shape: torch.Size([1, 500004]), batch_output_shape: torch.Size([2, 500004])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 21:42:04.323\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 21:42:04.858\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_max, checkpoint: roberta-base, output_dim: 1536, output_shape: torch.Size([1, 1536]), batch_output_shape: torch.Size([2, 1536])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-11-23 21:42:10.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 21:42:10.619\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_max, checkpoint: xlm-roberta-base, output_dim: 500004, output_shape: torch.Size([1, 500004]), batch_output_shape: torch.Size([2, 500004])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 21:42:12.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 21:42:12.824\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, checkpoint: roberta-base, output_dim: 2304, output_shape: torch.Size([1, 2304]), batch_output_shape: torch.Size([2, 2304])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-11-23 21:42:18.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, checkpoint: xlm-roberta-base, output_dim: 750006, output_shape: torch.Size([1, 750006]), batch_output_shape: torch.Size([2, 750006])\n"
     ]
    }
   ],
   "source": [
    "for pooler in [\"cls\", \"mean\", \"max\", \"mean_max\", \"cls_mean\", \"cls_max\", \"cls_mean_max\"]:\n",
    "    for checkpoint in [\"roberta-base\", \"xlm-roberta-base\"]:\n",
    "        robert = robert_family(checkpoint=checkpoint, pooling=pooler)\n",
    "        print(f\"pooler: {pooler}, checkpoint: {checkpoint}, output_dim: {robert.output_dim}, output_shape: {robert(tokenizer(sample_test, return_tensors='pt', padding=True)).shape}, batch_output_shape: {robert(tokenizer(batch_sample_test, return_tensors='pt', padding=True)).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-23 21:42:18.532\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 21:42:20.184\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    robert_family(checkpoint=\"roberta-base\", pooling=\"Wrong\")\n",
    "    assert False\n",
    "except ValueError:\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-23 22:26:24.568\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n",
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "xFormers not available\n",
      "xFormers not available\n",
      "\u001b[32m2023-11-23 22:26:27.402\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:26:29.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:26:29.777\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = ClipAligner(\n",
    "    DinoVisionModel(checkpoint=\"dinov2_vitb14\", pooling=\"cls\"),\n",
    "    RobertaCaptionModel(checkpoint=\"roberta-base\", pooling=\"cls\"),\n",
    "    vision_layer=[(768, \"mlp\"), (512, \"mlp\")],\n",
    "    caption_layer=[(768, \"mlp\"), (512, \"mlp\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans, tokenizer = model.get_basic_transformations()\n",
    "trans = transforms.Compose(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimirzaigrajew/Documents/projects/ClipAligner/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    output_test = model(trans(sample_image), tokenizer(sample_test, return_tensors=\"pt\", padding=True))\n",
    "    output_batch_test = model(trans(batch_sample_image), tokenizer(batch_sample_test, return_tensors=\"pt\", padding=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512]),\n",
       " torch.Size([2, 512]),\n",
       " torch.Size([1, 512]),\n",
       " torch.Size([2, 512]),\n",
       " 512)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test[0].shape, output_batch_test[0].shape, output_test[1].shape, output_batch_test[1].shape, model.output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-23 22:29:05.693\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:29:08.724\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:29:11.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:11.301\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "/Users/vladimirzaigrajew/Documents/projects/ClipAligner/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "\u001b[32m2023-11-23 22:29:11.631\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, vision_layer: [(768, 'mlp'), (512, 'mlp')], caption_layer: [(768, 'mlp'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:29:13.950\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:29:15.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:15.472\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:15.796\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, vision_layer: [(768, 'mlp'), (512, 'mlp')], caption_layer: [(768, 'mlp'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:29:18.301\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:29:19.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:19.885\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:20.286\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, vision_layer: [(768, 'mlp'), (512, 'mlp')], caption_layer: [(768, 'mlp'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:29:22.946\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:29:24.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:24.765\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:25.105\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, vision_layer: [(768, 'mlp'), (512, 'mlp')], caption_layer: [(768, 'mlp'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:29:27.432\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:29:28.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:28.921\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:29.234\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, vision_layer: [(768, 'conv'), (512, 'conv')], caption_layer: [(768, 'conv'), (512, 'conv')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:29:31.753\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:29:33.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:33.688\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:34.178\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, vision_layer: [(768, 'conv'), (512, 'conv')], caption_layer: [(768, 'conv'), (512, 'conv')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:29:37.275\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:29:39.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:39.054\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:39.697\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, vision_layer: [(768, 'conv'), (512, 'conv')], caption_layer: [(768, 'conv'), (512, 'conv')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:29:42.555\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:29:44.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:44.192\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:44.520\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, vision_layer: [(768, 'conv'), (512, 'conv')], caption_layer: [(768, 'conv'), (512, 'conv')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:29:47.060\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:29:48.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:48.648\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:49.036\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, vision_layer: [(768, 'res'), (512, 'res')], caption_layer: [(768, 'res'), (512, 'res')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:29:51.274\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:29:52.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:52.832\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:53.166\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, vision_layer: [(768, 'res'), (512, 'res')], caption_layer: [(768, 'res'), (512, 'res')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:29:55.566\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:29:57.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:57.247\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:29:57.642\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, vision_layer: [(768, 'res'), (512, 'res')], caption_layer: [(768, 'res'), (512, 'res')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:30:00.081\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:30:01.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:01.693\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:02.243\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, vision_layer: [(768, 'res'), (512, 'res')], caption_layer: [(768, 'res'), (512, 'res')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:30:04.829\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:30:06.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:06.748\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:07.646\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, vision_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], caption_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], output_dim: 256, output_shape_image: torch.Size([1, 256]), output_shape_caption: torch.Size([1, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:30:10.936\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:30:13.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:13.220\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:13.698\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, vision_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], caption_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], output_dim: 256, output_shape_image: torch.Size([1, 256]), output_shape_caption: torch.Size([1, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:30:17.383\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:30:19.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:19.255\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:19.777\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, vision_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], caption_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], output_dim: 256, output_shape_image: torch.Size([1, 256]), output_shape_caption: torch.Size([1, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:30:22.978\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:30:24.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:24.833\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:25.381\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, vision_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], caption_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], output_dim: 256, output_shape_image: torch.Size([1, 256]), output_shape_caption: torch.Size([1, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:30:28.385\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:30:31.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:31.135\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:31.704\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, vision_layer: [(768, 'conv'), (512, 'mlp')], caption_layer: [(768, 'res'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:30:34.570\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:30:36.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:36.277\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:36.832\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, vision_layer: [(768, 'conv'), (512, 'mlp')], caption_layer: [(768, 'res'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:30:39.488\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:30:41.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:41.219\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:41.593\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, vision_layer: [(768, 'conv'), (512, 'mlp')], caption_layer: [(768, 'res'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:30:44.237\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:30:45.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:30:45.763\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, vision_layer: [(768, 'conv'), (512, 'mlp')], caption_layer: [(768, 'res'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    for vision_layer, caption_layer in [\n",
    "        ([(768, \"mlp\"), (512, \"mlp\")], [(768, \"mlp\"), (512, \"mlp\")]),\n",
    "        ([(768, \"conv\"), (512, \"conv\")], [(768, \"conv\"), (512, \"conv\")]),\n",
    "        ([(768, \"res\"), (512, \"res\")], [(768, \"res\"), (512, \"res\")]),\n",
    "        ([(768, \"res\"), (512, \"conv\"), (256, \"mlp\")], [(768, \"res\"), (512, \"conv\"), (256, \"mlp\")]),\n",
    "        ([(768, \"conv\"), (512, \"mlp\")], [(768, \"res\"), (512, \"mlp\")]),\n",
    "    ]:\n",
    "        for pooler in [\"cls\", \"mean\", \"mean_max\", \"cls_mean_max\"]:\n",
    "            model = ClipAligner(\n",
    "                DinoVisionModel(checkpoint=\"dinov2_vitb14\", pooling=pooler),\n",
    "                RobertaCaptionModel(checkpoint=\"roberta-base\", pooling=\"cls\"),\n",
    "                vision_layer=vision_layer,\n",
    "                caption_layer=caption_layer,\n",
    "            )\n",
    "            output = model(trans(sample_image), tokenizer(sample_test, return_tensors=\"pt\", padding=True))\n",
    "            print(f\"pooler: {pooler}, vision_layer: {vision_layer}, caption_layer: {caption_layer}, output_dim: {model.output_dim}, output_shape_image: {output[0].shape}, output_shape_caption: {output[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-23 22:38:12.364\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n",
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:38:16.588\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:38:19.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:38:19.448\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:38:19.588\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n",
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-11-23 22:38:22.267\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:38:24.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:38:24.412\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m52\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for layer_vision, layer_caption in [[\"mlp\", \"Wrong\"], [\"Wrong\", \"mlp\"]]:\n",
    "    try:\n",
    "        model = ClipAligner(\n",
    "            DinoVisionModel(checkpoint=\"dinov2_vitb14\", pooling=\"cls\"),\n",
    "            RobertaCaptionModel(checkpoint=\"roberta-base\", pooling=\"cls\"),\n",
    "            vision_layer=[(768, layer_vision), (512, layer_vision)],\n",
    "            caption_layer=[(768, layer_caption), (512, layer_caption)],\n",
    "        )\n",
    "        assert False\n",
    "    except ValueError:\n",
    "        assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.factory import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-23 22:59:06.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.factory\u001b[0m:\u001b[36mcreate_model\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mInitializing Vision model: dinov2 and Caption model: roberta\u001b[0m\n",
      "\u001b[32m2023-11-23 22:59:06.724\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n",
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "xFormers not available\n",
      "xFormers not available\n",
      "\u001b[32m2023-11-23 22:59:09.590\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-11-23 22:59:12.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-11-23 22:59:12.443\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = create_model(\n",
    "    {\n",
    "        \"image\": {\"name\": \"dinov2\", \"checkpoint\": \"dinov2_vitb14\", \"pooling\": \"cls\"},\n",
    "        \"caption\": {\"name\": \"roberta\", \"checkpoint\": \"roberta-base\", \"pooling\": \"cls\"},\n",
    "        \"alignment\": {\"name\": \"clip_aligner\",\"vision_layer\": [(768, \"mlp\"), (512, \"mlp\")], \"caption_layer\": [(768, \"mlp\"), (512, \"mlp\")]},\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans, tokenizer = model.get_basic_transformations()\n",
    "trans = transforms.Compose(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimirzaigrajew/Documents/projects/ClipAligner/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    output_test = model(trans(sample_image), tokenizer(sample_test, return_tensors=\"pt\", padding=True))\n",
    "    output_batch_test = model(trans(batch_sample_image), tokenizer(batch_sample_test, return_tensors=\"pt\", padding=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512]),\n",
       " torch.Size([2, 512]),\n",
       " torch.Size([1, 512]),\n",
       " torch.Size([2, 512]),\n",
       " 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test[0].shape, output_batch_test[0].shape, output_test[1].shape, output_batch_test[1].shape, model.output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
