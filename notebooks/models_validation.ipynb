{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.10.5 (main, Dec 17 2022, 19:41:24) [Clang 14.0.0 (clang-1400.0.29.202)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "print('Python version:', sys.version)\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.models.models import *\n",
    "from src.models.aligner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = torch.rand(1, 3, 224, 224)\n",
    "sample_test = [\"Wlazl kotek na plotek i mruga\"]\n",
    "batch_sample_image = torch.rand(2, 3, 224, 224)\n",
    "batch_sample_test = [\"Wlazl kotek na plotek i mruga\", \"Wlazl kotek na plotek i mruga na ciebie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dinov2_vits14': (384, 256),\n",
       " 'dinov2_vitb14': (768, 256),\n",
       " 'dinov2_vitl14': (1024, 256),\n",
       " 'dinov2_vitg14': (1536, 256)}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dino_family = DinoVisionModel\n",
    "dino_family.SHAPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-05 12:56:53.016\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n",
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "xFormers not available\n",
      "xFormers not available\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DinoVisionModel(\n",
       "  (_model): DinoVisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x NestedTensorBlock(\n",
       "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): MemEffAttention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "    (head): Identity()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dino = dino_family(checkpoint=\"dinov2_vitb14\", pooling=\"cls\")\n",
    "base_dino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimirzaigrajew/Documents/projects/ClipAligner/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 224, 224]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans = transforms.Compose(base_dino.get_transformations()['image'])\n",
    "trans(sample_image).shape, base_dino(sample_image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    output_image = base_dino(trans(sample_image))\n",
    "    output_batch_image = base_dino(trans(batch_sample_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 768]), torch.Size([2, 768]), 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_image.shape, output_batch_image.shape, base_dino.output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-05 13:00:34.030\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n",
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:00:35.766\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, checkpoint: dinov2_vits14, output_dim: 384, output_shape: torch.Size([1, 384]), batch_output_shape: torch.Size([2, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:00:40.476\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, checkpoint: dinov2_vitb14, output_dim: 768, output_shape: torch.Size([1, 768]), batch_output_shape: torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:00:41.770\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, checkpoint: dinov2_vits14, output_dim: 256, output_shape: torch.Size([1, 256]), batch_output_shape: torch.Size([2, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:00:47.035\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, checkpoint: dinov2_vitb14, output_dim: 256, output_shape: torch.Size([1, 256]), batch_output_shape: torch.Size([2, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:00:48.158\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: max, checkpoint: dinov2_vits14, output_dim: 256, output_shape: torch.Size([1, 256]), batch_output_shape: torch.Size([2, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:00:51.756\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: max, checkpoint: dinov2_vitb14, output_dim: 256, output_shape: torch.Size([1, 256]), batch_output_shape: torch.Size([2, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:00:53.128\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, checkpoint: dinov2_vits14, output_dim: 512, output_shape: torch.Size([1, 512]), batch_output_shape: torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:00:56.857\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, checkpoint: dinov2_vitb14, output_dim: 512, output_shape: torch.Size([1, 512]), batch_output_shape: torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:00:58.192\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean, checkpoint: dinov2_vits14, output_dim: 640, output_shape: torch.Size([1, 640]), batch_output_shape: torch.Size([2, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:01:02.157\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean, checkpoint: dinov2_vitb14, output_dim: 1024, output_shape: torch.Size([1, 1024]), batch_output_shape: torch.Size([2, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:01:03.450\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_max, checkpoint: dinov2_vits14, output_dim: 640, output_shape: torch.Size([1, 640]), batch_output_shape: torch.Size([2, 640])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:01:06.824\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_max, checkpoint: dinov2_vitb14, output_dim: 1024, output_shape: torch.Size([1, 1024]), batch_output_shape: torch.Size([2, 1024])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:01:07.899\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, checkpoint: dinov2_vits14, output_dim: 896, output_shape: torch.Size([1, 896]), batch_output_shape: torch.Size([2, 896])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, checkpoint: dinov2_vitb14, output_dim: 1280, output_shape: torch.Size([1, 1280]), batch_output_shape: torch.Size([2, 1280])\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    for pooler in [\"cls\", \"mean\", \"max\", \"mean_max\", \"cls_mean\", \"cls_max\", \"cls_mean_max\"]:\n",
    "        for checkpoint in [\"dinov2_vits14\", \"dinov2_vitb14\"]:#, \"dinov2_vitl14\", \"dinov2_vitg14\"]:\n",
    "            dino = dino_family(checkpoint=checkpoint, pooling=pooler)\n",
    "            print(f\"pooler: {pooler}, checkpoint: {checkpoint}, output_dim: {dino.output_dim}, output_shape: {dino(sample_image).shape}, batch_output_shape: {dino(batch_sample_image).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-05 13:01:13.137\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n",
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dino_family(checkpoint=\"dinov2_vits14\", pooling=\"Wrong\")\n",
    "    assert False\n",
    "except ValueError:\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roberta-base': 768, 'roberta-large': 1024, 'xlm-roberta-base': 250002}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robert_family = RobertaCaptionModel\n",
    "robert_family.SHAPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-05 13:01:14.299\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:01:17.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaCaptionModel(\n",
       "  (_model): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_robert = robert_family(checkpoint=\"roberta-base\", pooling=\"cls\")\n",
    "base_robert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['input_ids', 'attention_mask']),\n",
       " dict_keys(['input_ids', 'attention_mask']))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = base_robert.get_transformations()['caption']\n",
    "tokenizer(sample_test, return_tensors=\"pt\", padding=True).keys(), tokenizer(batch_sample_test, return_tensors=\"pt\", padding=True).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "    output_test = base_robert(tokenizer(sample_test, return_tensors=\"pt\", padding=True))\n",
    "    output_batch_test = base_robert(tokenizer(batch_sample_test, return_tensors=\"pt\", padding=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 768]), torch.Size([2, 768]), 768)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test.shape, output_batch_test.shape, base_robert.output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-05 13:03:01.020\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:03:05.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:03:05.968\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, checkpoint: roberta-base, output_dim: 768, output_shape: torch.Size([1, 768]), batch_output_shape: torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-12-05 13:03:14.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:03:15.196\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, checkpoint: xlm-roberta-base, output_dim: 250002, output_shape: torch.Size([1, 250002]), batch_output_shape: torch.Size([2, 250002])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:03:17.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:03:18.600\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, checkpoint: roberta-base, output_dim: 768, output_shape: torch.Size([1, 15]), batch_output_shape: torch.Size([2, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-12-05 13:03:25.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:03:26.255\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, checkpoint: xlm-roberta-base, output_dim: 250002, output_shape: torch.Size([1, 15]), batch_output_shape: torch.Size([2, 19])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:03:29.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:03:31.009\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: max, checkpoint: roberta-base, output_dim: 768, output_shape: torch.Size([1, 768]), batch_output_shape: torch.Size([2, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-12-05 13:03:38.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:03:38.616\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: max, checkpoint: xlm-roberta-base, output_dim: 250002, output_shape: torch.Size([1, 250002]), batch_output_shape: torch.Size([2, 250002])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:03:40.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:03:41.363\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, checkpoint: roberta-base, output_dim: 1536, output_shape: torch.Size([1, 1536]), batch_output_shape: torch.Size([2, 1536])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-12-05 13:03:48.751\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:03:49.150\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, checkpoint: xlm-roberta-base, output_dim: 500004, output_shape: torch.Size([1, 500004]), batch_output_shape: torch.Size([2, 500004])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:03:52.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:03:53.654\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean, checkpoint: roberta-base, output_dim: 1536, output_shape: torch.Size([1, 1536]), batch_output_shape: torch.Size([2, 1536])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-12-05 13:04:00.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:04:01.189\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean, checkpoint: xlm-roberta-base, output_dim: 500004, output_shape: torch.Size([1, 500004]), batch_output_shape: torch.Size([2, 500004])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:04:02.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:04:03.856\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_max, checkpoint: roberta-base, output_dim: 1536, output_shape: torch.Size([1, 1536]), batch_output_shape: torch.Size([2, 1536])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-12-05 13:04:18.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:04:19.621\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_max, checkpoint: xlm-roberta-base, output_dim: 500004, output_shape: torch.Size([1, 500004]), batch_output_shape: torch.Size([2, 500004])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:04:22.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:04:23.903\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, checkpoint: roberta-base, output_dim: 2304, output_shape: torch.Size([1, 2304]), batch_output_shape: torch.Size([2, 2304])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "\u001b[32m2023-12-05 13:04:33.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, checkpoint: xlm-roberta-base, output_dim: 750006, output_shape: torch.Size([1, 750006]), batch_output_shape: torch.Size([2, 750006])\n"
     ]
    }
   ],
   "source": [
    "for pooler in [\"cls\", \"mean\", \"max\", \"mean_max\", \"cls_mean\", \"cls_max\", \"cls_mean_max\"]:\n",
    "    for checkpoint in [\"roberta-base\", \"xlm-roberta-base\"]:\n",
    "        robert = robert_family(checkpoint=checkpoint, pooling=pooler)\n",
    "        print(f\"pooler: {pooler}, checkpoint: {checkpoint}, output_dim: {robert.output_dim}, output_shape: {robert(tokenizer(sample_test, return_tensors='pt', padding=True)).shape}, batch_output_shape: {robert(tokenizer(batch_sample_test, return_tensors='pt', padding=True)).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-05 13:04:34.010\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:04:37.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    robert_family(checkpoint=\"roberta-base\", pooling=\"Wrong\")\n",
    "    assert False\n",
    "except ValueError:\n",
    "    assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-05 13:12:05.764\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n",
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:12:09.467\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:12:11.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:11.968\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = ClipAligner(\n",
    "    DinoVisionModel(checkpoint=\"dinov2_vitb14\", pooling=\"cls\"),\n",
    "    RobertaCaptionModel(checkpoint=\"roberta-base\", pooling=\"cls\"),\n",
    "    vision_layer=[(768, \"mlp\"), (512, \"mlp\")],\n",
    "    caption_layer=[(768, \"mlp\"), (512, \"mlp\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.get_transformations()\n",
    "trans, tokenizer = out['image'], out['caption']\n",
    "trans = transforms.Compose(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimirzaigrajew/Documents/projects/ClipAligner/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    output_test = model(trans(sample_image), tokenizer(sample_test, return_tensors=\"pt\", padding=True))\n",
    "    output_batch_test = model(trans(batch_sample_image), tokenizer(batch_sample_test, return_tensors=\"pt\", padding=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512]),\n",
       " torch.Size([2, 512]),\n",
       " torch.Size([1, 512]),\n",
       " torch.Size([2, 512]),\n",
       " 512)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test[0].shape, output_batch_test[0].shape, output_test[1].shape, output_batch_test[1].shape, model.output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-05 13:12:15.791\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:12:19.865\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:12:21.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:21.656\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:22.135\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, vision_layer: [(768, 'mlp'), (512, 'mlp')], caption_layer: [(768, 'mlp'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:12:25.466\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:12:27.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:27.328\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:27.685\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, vision_layer: [(768, 'mlp'), (512, 'mlp')], caption_layer: [(768, 'mlp'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:12:30.521\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:12:32.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:32.216\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:32.650\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, vision_layer: [(768, 'mlp'), (512, 'mlp')], caption_layer: [(768, 'mlp'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:12:35.507\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:12:37.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:37.600\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:37.976\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, vision_layer: [(768, 'mlp'), (512, 'mlp')], caption_layer: [(768, 'mlp'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:12:41.438\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:12:43.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:43.033\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:43.379\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, vision_layer: [(768, 'conv'), (512, 'conv')], caption_layer: [(768, 'conv'), (512, 'conv')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:12:46.495\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:12:48.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:48.542\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:48.936\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, vision_layer: [(768, 'conv'), (512, 'conv')], caption_layer: [(768, 'conv'), (512, 'conv')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:12:51.259\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:12:52.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:52.875\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:53.190\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, vision_layer: [(768, 'conv'), (512, 'conv')], caption_layer: [(768, 'conv'), (512, 'conv')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:12:55.524\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:12:57.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:57.397\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:12:57.818\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, vision_layer: [(768, 'conv'), (512, 'conv')], caption_layer: [(768, 'conv'), (512, 'conv')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:13:00.533\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:13:02.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:02.234\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:02.579\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, vision_layer: [(768, 'res'), (512, 'res')], caption_layer: [(768, 'res'), (512, 'res')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:13:04.815\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:13:06.417\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:06.418\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:06.828\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, vision_layer: [(768, 'res'), (512, 'res')], caption_layer: [(768, 'res'), (512, 'res')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:13:09.723\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:13:12.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:12.068\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:12.464\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, vision_layer: [(768, 'res'), (512, 'res')], caption_layer: [(768, 'res'), (512, 'res')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:13:15.246\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:13:16.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:16.878\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:17.225\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, vision_layer: [(768, 'res'), (512, 'res')], caption_layer: [(768, 'res'), (512, 'res')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:13:20.217\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:13:21.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:21.880\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:22.272\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, vision_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], caption_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], output_dim: 256, output_shape_image: torch.Size([1, 256]), output_shape_caption: torch.Size([1, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:13:24.944\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:13:26.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:26.611\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:27.006\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, vision_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], caption_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], output_dim: 256, output_shape_image: torch.Size([1, 256]), output_shape_caption: torch.Size([1, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:13:29.930\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:13:31.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:31.438\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:31.761\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, vision_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], caption_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], output_dim: 256, output_shape_image: torch.Size([1, 256]), output_shape_caption: torch.Size([1, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:13:34.136\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:13:35.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:35.911\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:36.268\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, vision_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], caption_layer: [(768, 'res'), (512, 'conv'), (256, 'mlp')], output_dim: 256, output_shape_image: torch.Size([1, 256]), output_shape_caption: torch.Size([1, 256])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:13:38.858\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:13:40.525\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:40.526\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:40.844\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls, vision_layer: [(768, 'conv'), (512, 'mlp')], caption_layer: [(768, 'res'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:13:44.118\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:13:45.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:45.758\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:46.212\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean, vision_layer: [(768, 'conv'), (512, 'mlp')], caption_layer: [(768, 'res'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:13:49.026\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:13:50.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:50.968\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:51.357\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: mean_max, vision_layer: [(768, 'conv'), (512, 'mlp')], caption_layer: [(768, 'res'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:13:53.710\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:13:55.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:13:55.480\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pooler: cls_mean_max, vision_layer: [(768, 'conv'), (512, 'mlp')], caption_layer: [(768, 'res'), (512, 'mlp')], output_dim: 512, output_shape_image: torch.Size([1, 512]), output_shape_caption: torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    for vision_layer, caption_layer in [\n",
    "        ([(768, \"mlp\"), (512, \"mlp\")], [(768, \"mlp\"), (512, \"mlp\")]),\n",
    "        ([(768, \"conv\"), (512, \"conv\")], [(768, \"conv\"), (512, \"conv\")]),\n",
    "        ([(768, \"res\"), (512, \"res\")], [(768, \"res\"), (512, \"res\")]),\n",
    "        ([(768, \"res\"), (512, \"conv\"), (256, \"mlp\")], [(768, \"res\"), (512, \"conv\"), (256, \"mlp\")]),\n",
    "        ([(768, \"conv\"), (512, \"mlp\")], [(768, \"res\"), (512, \"mlp\")]),\n",
    "    ]:\n",
    "        for pooler in [\"cls\", \"mean\", \"mean_max\", \"cls_mean_max\"]:\n",
    "            model = ClipAligner(\n",
    "                DinoVisionModel(checkpoint=\"dinov2_vitb14\", pooling=pooler),\n",
    "                RobertaCaptionModel(checkpoint=\"roberta-base\", pooling=\"cls\"),\n",
    "                vision_layer=vision_layer,\n",
    "                caption_layer=caption_layer,\n",
    "            )\n",
    "            output = model(trans(sample_image), tokenizer(sample_test, return_tensors=\"pt\", padding=True))\n",
    "            print(f\"pooler: {pooler}, vision_layer: {vision_layer}, caption_layer: {caption_layer}, output_dim: {model.output_dim}, output_shape_image: {output[0].shape}, output_shape_caption: {output[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-12-05 13:13:55.861\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n",
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:13:58.311\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:14:00.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:14:00.072\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:14:00.215\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m16\u001b[0m - \u001b[34m\u001b[1mModel image DinoVisionModel initialized.\u001b[0m\n",
      "Using cache found in /Users/vladimirzaigrajew/.cache/torch/hub/facebookresearch_dinov2_main\n",
      "\u001b[32m2023-12-05 13:14:02.989\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m32\u001b[0m - \u001b[34m\u001b[1mModel caption RobertaCaptionModel initialized.\u001b[0m\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[32m2023-12-05 13:14:04.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.models.models\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m84\u001b[0m - \u001b[1mSssssh don't listen to the warning above, Robert can be grumpy.\u001b[0m\n",
      "\u001b[32m2023-12-05 13:14:04.662\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36msrc.models.base\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m50\u001b[0m - \u001b[34m\u001b[1mModel image-caption ClipAligner initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for layer_vision, layer_caption in [[\"mlp\", \"Wrong\"], [\"Wrong\", \"mlp\"]]:\n",
    "    try:\n",
    "        model = ClipAligner(\n",
    "            DinoVisionModel(checkpoint=\"dinov2_vitb14\", pooling=\"cls\"),\n",
    "            RobertaCaptionModel(checkpoint=\"roberta-base\", pooling=\"cls\"),\n",
    "            vision_layer=[(768, layer_vision), (512, layer_vision)],\n",
    "            caption_layer=[(768, layer_caption), (512, layer_caption)],\n",
    "        )\n",
    "        assert False\n",
    "    except ValueError:\n",
    "        assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.factory import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m(\n\u001b[1;32m      2\u001b[0m     {\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdinov2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdinov2_vitb14\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpooling\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaption\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcheckpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroberta-base\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpooling\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malignment\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclip_aligner\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvision_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m768\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m\"\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m512\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m}],\n\u001b[1;32m      7\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcaption_layer\u001b[39m\u001b[38;5;124m\"\u001b[39m: [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m768\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtanh\u001b[39m\u001b[38;5;124m\"\u001b[39m}, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m512\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m}], \n\u001b[1;32m      8\u001b[0m         },\n\u001b[1;32m      9\u001b[0m     }\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_model' is not defined"
     ]
    }
   ],
   "source": [
    "model = create_model(\n",
    "    {\n",
    "        \"image\": {\"name\": \"dinov2\", \"checkpoint\": \"dinov2_vitb14\", \"pooling\": \"cls\"},\n",
    "        \"caption\": {\"name\": \"roberta\", \"checkpoint\": \"roberta-base\", \"pooling\": \"cls\"},\n",
    "        \"alignment\": {\"name\": \"clip_aligner\",\n",
    "                      \"vision_layer\": [{\"name\": \"mlp\", \"output\": 768, \"activation\": \"tanh\"}, {\"name\": \"mlp\", \"output\": 512, \"activation\": \"\"}],\n",
    "                      \"caption_layer\": [{\"name\": \"mlp\", \"output\": 768, \"activation\": \"tanh\"}, {\"name\": \"mlp\", \"output\": 512, \"activation\": \"\"}], \n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.get_transformations()\n",
    "trans, tokenizer = out['image'], out['caption']\n",
    "trans = transforms.Compose(trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladimirzaigrajew/Documents/projects/ClipAligner/.venv/lib/python3.10/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "with torch.inference_mode():\n",
    "    output_test = model(trans(sample_image), tokenizer(sample_test, return_tensors=\"pt\", padding=True))\n",
    "    output_batch_test = model(trans(batch_sample_image), tokenizer(batch_sample_test, return_tensors=\"pt\", padding=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 512]),\n",
       " torch.Size([2, 512]),\n",
       " torch.Size([1, 512]),\n",
       " torch.Size([2, 512]),\n",
       " 512)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test[0].shape, output_batch_test[0].shape, output_test[1].shape, output_batch_test[1].shape, model.output_dim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
